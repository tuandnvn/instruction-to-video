{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import TimeDistributed, LSTM, Dense, RepeatVector\n",
    "from numpy import array, array_equal, argmax\n",
    "import tensorflow as tf\n",
    "import attention_decoder\n",
    "\n",
    "\"\"\"\n",
    "Sample keras model\n",
    "\"\"\"\n",
    "def create_model_1():\n",
    "    Note = Input(shape=(sequence_length, n_vocab), dtype = 'float32')\n",
    "    y = LSTM(400, input_shape = (sequence_length, n_vocab), return_sequences = True ) (Note)\n",
    "    y = Dropout(0.4) (y)\n",
    "    y = LSTM(400) (y)\n",
    "    y = Dropout(0.4) (y)\n",
    "    # Two weights, two bias\n",
    "    # If coordinates of input is (X1, X2), and this layer is (Y1, Y2, Y3, Y4)\n",
    "    # Result would be \n",
    "    y1 = Lambda(lambda x: x*2)( Dense(2, activation = 'tanh') (y) )\n",
    "    y2 = Dense(2, activation = 'linear') (y)\n",
    "    Coordinates = Input(shape= (2, ), dtype = 'float32')\n",
    "    print (keras.backend.shape(y1))\n",
    "    print (keras.backend.shape(Coordinates))\n",
    "    c1 = Multiply()([y1, Coordinates])\n",
    "    c = Add()([y2, c1])\n",
    "    m = Model(inputs = [Note, Coordinates], outputs = c)\n",
    "\n",
    "    print (m.summary())\n",
    "    m.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return m\n",
    "\n",
    "def create_sample_attention_model () :\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(150, input_shape=(n_timesteps_in, n_features), return_sequences=True))\n",
    "    model.add(attention_decoder.AttentionDecoder(150, n_features))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like for this problem, I need to use Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_ta = tf.TensorArray(size=784, dtype=tf.float32)  # store trained/sampled pixel\n",
    "def loop_fn(time, cell_output, cell_state, loop_state):\n",
    "    emit_output = cell_output  # == None for time == 0\n",
    "    if cell_output is None:\n",
    "        # time=0, everything here will be used for initialization only\n",
    "        next_cell_state = cell_init_state\n",
    "        next_pixel = cell_init_pixel\n",
    "        next_loop_state = output_ta\n",
    "    else:  \n",
    "        # pass the last state to the next\n",
    "        next_cell_state = cell_state\n",
    "        next_pixel = tf.cond(is_training,\n",
    "                         lambda: inputs_ta.read(time - 1),\n",
    "                         lambda: tf.contrib.distributions.Bernoulli(\n",
    "                             probs=tf.nn.sigmoid(tf.layers.dense(cell_output, 1, \n",
    "                                 name='output_to_p', activation=tf.nn.sigmoid,\n",
    "                                 reuse=True)),\n",
    "                             dtype=tf.float32).sample())\n",
    "        next_loop_state = loop_state.write(time - 1, next_pixel)\n",
    "    elements_finished = (time >= 784)\n",
    "    return (elements_finished, next_pixel, next_cell_state,\n",
    "            emit_output, next_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.rnn import _transpose_batch_time\n",
    "\n",
    "def sampling_rnn(self, cell, initial_state, input_, seq_lengths):\n",
    "\n",
    "    # raw_rnn expects time major inputs as TensorArrays\n",
    "    max_time = ...  # this is the max time step per batch\n",
    "    inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_time, clear_after_read=False)\n",
    "    inputs_ta = inputs_ta.unstack(_transpose_batch_time(input_))  # model_input is the input placeholder\n",
    "    input_dim = input_.get_shape()[-1].value  # the dimensionality of the input to each time step\n",
    "    output_dim = ...  # the dimensionality of the model's output at each time step\n",
    "    \n",
    "    def loop_fn(time, cell_output, cell_state, loop_state):\n",
    "        \"\"\"\n",
    "        Loop function that allows to control input to the rnn cell and manipulate cell outputs.\n",
    "        :param time: current time step\n",
    "        :param cell_output: output from previous time step or None if time == 0\n",
    "        :param cell_state: cell state from previous time step\n",
    "        :param loop_state: custom loop state to share information between different iterations of this loop fn\n",
    "        :return: tuple consisting of\n",
    "          elements_finished: tensor of size [bach_size] which is True for sequences that have reached their end,\n",
    "            needed because of variable sequence size\n",
    "          next_input: input to next time step\n",
    "          next_cell_state: cell state forwarded to next time step\n",
    "          emit_output: The first return argument of raw_rnn. This is not necessarily the output of the RNN cell,\n",
    "            but could e.g. be the output of a dense layer attached to the rnn layer.\n",
    "          next_loop_state: loop state forwarded to the next time step\n",
    "        \"\"\"\n",
    "        if cell_output is None:\n",
    "            # time == 0, used for initialization before first call to cell\n",
    "            next_cell_state = initial_state\n",
    "            # the emit_output in this case tells TF how future emits look\n",
    "            emit_output = tf.zeros([output_dim])\n",
    "        else:\n",
    "            # t > 0, called right after call to cell, i.e. cell_output is the output from time t-1.\n",
    "            # here you can do whatever ou want with cell_output before assigning it to emit_output.\n",
    "            # In this case, we don't do anything\n",
    "            next_cell_state = cell_state\n",
    "            emit_output = cell_output  \n",
    "\n",
    "        # check which elements are finished\n",
    "        elements_finished = (time >= seq_lengths)\n",
    "        finished = tf.reduce_all(elements_finished)\n",
    "\n",
    "        # assemble cell input for upcoming time step\n",
    "        current_output = emit_output if cell_output is not None else None\n",
    "        input_original = inputs_ta.read(time)  # tensor of shape (None, input_dim)\n",
    "\n",
    "        if current_output is None:\n",
    "            # this is the initial step, i.e. there is no output from a previous time step, what we feed here\n",
    "            # can highly depend on the data. In this case we just assign the actual input in the first time step.\n",
    "            next_in = input_original\n",
    "        else:\n",
    "            # time > 0, so just use previous output as next input\n",
    "            # here you could do fancier things, whatever you want to do before passing the data into the rnn cell\n",
    "            # if here you were to pass input_original than you would get the normal behaviour of dynamic_rnn\n",
    "            next_in = current_output\n",
    "\n",
    "        next_input = tf.cond(finished,\n",
    "                             lambda: tf.zeros([self.batch_size, input_dim], dtype=tf.float32),  # copy through zeros\n",
    "                             lambda: next_in)  # if not finished, feed the previous output as next input\n",
    "\n",
    "        # set shape manually, otherwise it is not defined for the last dimensions\n",
    "        next_input.set_shape([None, input_dim])\n",
    "\n",
    "        # loop state not used in this example\n",
    "        next_loop_state = None\n",
    "        return (elements_finished, next_input, next_cell_state, emit_output, next_loop_state)\n",
    "\n",
    "    outputs_ta, last_state, _ = tf.nn.raw_rnn(cell, loop_fn)\n",
    "    outputs = _transpose_batch_time(outputs_ta.stack())\n",
    "    final_state = last_state\n",
    "\n",
    "    return outputs, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image size \n",
    "\n",
    "(288, 432, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(os.path.join('..', 'target', '0', '0.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_and_resize (frame):\n",
    "    \n",
    "    # cv2.resize(frame, (10, 10), interpolation = cv2.INTER_AREA)\n",
    "#     return frame[36:250, 114:328, :]\n",
    "    return cv2.resize(frame[36:250, 114:328, :], (15, 15), interpolation = cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "counter = 0\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    data.append(crop_and_resize(frame))\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-e3ca9b474a6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pl.imshow(data[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get instruction signal\n",
    "\n",
    "Parse the video file into instruction sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "instruction_dict = {'north': 0, 'east': 1, 'south': 2, 'west': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_instruction_dict = dict((v,k) for (k,v) in instruction_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode ( sequence ):\n",
    "    return ','.join([reverse_instruction_dict[s] for s in sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instruction_btw_frame( prev_frame, cur_frame ):\n",
    "    diff = abs(prev_frame.astype(np.int32) - cur_frame.astype(np.int32))\n",
    "    vals = np.argwhere(diff >= 20)\n",
    "    \n",
    "    points = set()\n",
    "    for val in vals:\n",
    "        points.add(tuple(val[:2]))\n",
    "    \n",
    "    # if prev_frame[points[0]] ~ (255,255,255), points[0] is target, points[1] is start\n",
    "    # otherwise reverse\n",
    "    \n",
    "    points = list(points)\n",
    "    \n",
    "    if np.sum(abs(prev_frame[points[0]].astype(np.int32) - np.array([255, 255, 255]))) > 20:\n",
    "        source = np.array(points[0])\n",
    "        target = np.array(points[1])\n",
    "    else:\n",
    "        source = np.array(points[1])\n",
    "        target = np.array(points[0])\n",
    "\n",
    "        \n",
    "    if np.array_equal(target - source , [0, 1]):\n",
    "        return 1\n",
    "    if np.array_equal(target - source , [0, -1]):\n",
    "        return 3\n",
    "    if np.array_equal(target - source , [1, 0]):\n",
    "        return 2\n",
    "    if np.array_equal(target - source , [-1, 0]):\n",
    "        return 0\n",
    "        \n",
    "\n",
    "def get_instructions ( video_path, debug = True ):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    prev_frame = None\n",
    "    instructions = []\n",
    "\n",
    "    counter = 0\n",
    "    while (cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        c_frame = crop_and_resize(frame)\n",
    "        \n",
    "        # Get the instruction between prev_frame and frame\n",
    "        if prev_frame is not None:\n",
    "            instruction = get_instruction_btw_frame (prev_frame, c_frame)\n",
    "            instructions.append(instruction)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        prev_frame = c_frame\n",
    "        \n",
    "    #pl.imshow(prev_frame)\n",
    "    \n",
    "    if debug :\n",
    "        print ('There are %d frames ' % counter)\n",
    "        print ('The list of instructions are %s ' % decode( instructions ))\n",
    "    \n",
    "    return instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19 frames \n",
      "The list of instructions are south,south,south,south,south,south,west,west,south,south,west,west,west,west,west,west,south,west \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_instructions(os.path.join('..', 'target', '0', '0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "\n",
    "LSTM model with attention with the image being additional input to encoded vector.\n",
    "\n",
    "The simplest model would have image flattened out into an 100-cell vectors. Colors are coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\n    return importlib.import_module(mname)\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\n    return importlib.import_module('_pywrap_tensorflow_internal')\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mcreate_module\u001b[1;34m(self, spec)\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '_pywrap_tensorflow_internal'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-94749744df3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_cell\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBasicLSTMCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropoutWrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiRNNCell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Protocol buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[1;32m---> 74\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\n    return importlib.import_module(mname)\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\n    return importlib.import_module('_pywrap_tensorflow_internal')\n  File \"c:\\anaconda3\\envs\\tensorflow18\\lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    from tensorflow.nn.rnn_cell import BasicLSTMCell, DropoutWrapper, MultiRNNCell\n",
    "except:\n",
    "    from tensorflow.contrib.rnn import BasicLSTMCell, DropoutWrapper, MultiRNNCell\n",
    "\n",
    "import stateful_lstm\n",
    "\n",
    "\"\"\"\n",
    "A template class for all LSTM classes\n",
    "\"\"\"\n",
    "class EncoderDecoder(object):\n",
    "    def __init__(self, is_training, name=None, config = None):\n",
    "        self.config = config\n",
    "        self.input_num_steps = input_num_steps = config.input_num_steps\n",
    "        self.output_num_steps = output_num_steps = config.output_num_steps\n",
    "        self.n_input = n_input = config.n_input\n",
    "        self.n_output = n_output = config.n_output\n",
    "        self.size = size = config.hidden_size\n",
    "\n",
    "        # This is an option, if self.s2s = True -> Use all progress values\n",
    "        # otherwise just use the last progress value\n",
    "        self.s2s = config.s2s \n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            \"Declare all placeholders\"\n",
    "            \"Placeholder for input\"\n",
    "            \n",
    "            \"\"\"\n",
    "            batch_size\n",
    "            input_num_steps: length of sequence\n",
    "            n_input: size of feature vectors\n",
    "            \"\"\"\n",
    "            self._input_data = tf.placeholder(tf.float32, [None, input_num_steps, n_input])\n",
    "            \n",
    "            \"\"\"\n",
    "            (batch_size x output_num_steps) for sequence to sequence\n",
    "            \"\"\"\n",
    "            self._targets = tf.placeholder(tf.float32, [None, output_num_steps, n_output])\n",
    "\n",
    "            # Sample's weights, NOT network's weights\n",
    "            self._weights = tf.placeholder(tf.float32, [None])\n",
    "                \n",
    "            \n",
    "            if is_training:\n",
    "                self.lr = tf.Variable(0.0, trainable=False)\n",
    "            \n",
    "            lstm_cell = BasicLSTMCell(size, forget_bias = 1.0, state_is_tuple=True)\n",
    "            \n",
    "            if is_training and config.keep_prob < 1:\n",
    "                lstm_cell = DropoutWrapper(lstm_cell, output_keep_prob=config.keep_prob)\n",
    "                \n",
    "            multi_lstm_cell = MultiRNNCell([lstm_cell] * config.num_layers, state_is_tuple=True)\n",
    "\n",
    "            self.initial_state = multi_lstm_cell.zero_state(config.batch_size, tf.float32)\n",
    "\n",
    "            inputs = tf.reshape(self._input_data, [-1, n_input]) # (batch_size * input_num_steps, n_input)\n",
    "            \n",
    "            with tf.variable_scope(\"linear\"):\n",
    "                weight = tf.get_variable(\"weight\", [n_input, size])\n",
    "                bias = tf.get_variable(\"bias\", [size])\n",
    "\n",
    "                # (batch_size * input_num_steps, size)\n",
    "                inputs = tf.matmul(inputs, weight) + bias\n",
    "                \n",
    "            inputs = tf.reshape(inputs, (-1, input_num_steps, size)) # (batch_size, input_num_steps, size)\n",
    "            \n",
    "            print (\"self.inputs.shape = %s \" % str(inputs.shape) + \" after linear layer\")\n",
    "\n",
    "            # (output, state)\n",
    "            # output is of size:  ( batch_size, input_num_steps, size )\n",
    "            # state is of size:   ( batch_size, cell.state_size ) (last state only)\n",
    "            with tf.variable_scope(\"lstm\"):\n",
    "                output_and_state = tf.nn.dynamic_rnn(multi_lstm_cell, inputs, dtype=tf.float32,\n",
    "                                                     initial_state = self.initial_state)\n",
    "            \n",
    "            self.final_state = output_and_state[1]\n",
    "            \n",
    "            # ( batch_size, num_steps, size )\n",
    "            output = output_and_state[0]\n",
    "                \n",
    "            print (\"output.shape = %s after LSTM\" % str(output.shape))\n",
    "            \n",
    "            with tf.variable_scope(\"output_linear\"):\n",
    "                weight = tf.get_variable(\"weight\", [size, n_output])\n",
    "                bias = tf.get_variable(\"bias\", [n_output])\n",
    "\n",
    "                \n",
    "                if self.s2s:\n",
    "                    # Need to reshape to 2 dimensions\n",
    "                    output = tf.reshape(output, [-1, size])\n",
    "                    output = tf.matmul(output, weight) + bias\n",
    "                    # ( batch_size, num_steps, n_output )  \n",
    "                    output = tf.reshape(output, [-1, num_steps])\n",
    "                else:\n",
    "                    #( batch_size, n_output)\n",
    "                    # @ is the same as matmul\n",
    "                    output = tf.matmul(output, weight) + bias\n",
    "                    \n",
    "            # Remove all 1 dimension and squash the function down to [0..1]\n",
    "            # ( batch_size, output_num_steps, n_output ) or (batch_size, n_output)\n",
    "            self.output = tf.sigmoid(output)\n",
    "            \n",
    "            print (\"self.output.shape = %s after linear\" % str(self.output.shape))\n",
    "            \n",
    "            print (\"self._targets.shape = %s \" % str(self._targets.shape))\n",
    "            \n",
    "            # Loss = mean squared error of target and predictions\n",
    "            self.loss = tf.losses.mean_squared_error(self._targets, self.output, self._weights)\n",
    "            \n",
    "            if is_training:\n",
    "                # \n",
    "                # optimizer = tf.train.AdagradOptimizer(learning_rate=self.lr)\n",
    "                \n",
    "                # self.train_op = optimizer.minimize(self.loss)\n",
    "\n",
    "                if self.config.optimizer == 'sgd':\n",
    "                    optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.lr)\n",
    "                    tvars = tf.trainable_variables()\n",
    "                    self.train_op = []\n",
    "                        \n",
    "                    grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss, tvars),\n",
    "                                                      self.config.max_grad_norm)\n",
    "                    self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "                elif self.config.optimizer == 'adam':\n",
    "                    optimizer = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
    "                    \n",
    "                    self.train_op = optimizer.minimize(self.loss)\n",
    "\n",
    "                elif self.config.optimizer == 'adagrad':\n",
    "                    optimizer = tf.train.AdagradOptimizer(learning_rate=self.lr)\n",
    "                    \n",
    "                    self.train_op = optimizer.minimize(self.loss)\n",
    "\n",
    "    def checkInputs(self, inputs):\n",
    "        \"\"\"\n",
    "        time-major is False\n",
    "        \"\"\"\n",
    "        assert isinstance(inputs, np.ndarray)\n",
    "        \n",
    "        assert len(inputs.shape) == 3\n",
    "        assert inputs.shape[1] == self.input_num_steps\n",
    "        assert inputs.shape[2] == self.n_input\n",
    "    \n",
    "    def checkOutputs(self, outputs, batch_size):\n",
    "        assert isinstance(outputs, np.ndarray)\n",
    "\n",
    "        assert len(outputs.shape) == 3\n",
    "        assert outputs.shape[0] == batch_size\n",
    "        assert outputs.shape[1] == self.output_num_steps\n",
    "        assert outputs.shape[2] == self.n_output\n",
    "        \n",
    "    def update(self, inputs, outputs, weights = None, initial_state = None, sess=None):\n",
    "        \"\"\"\n",
    "        inputs: np.array (batch_size, num_steps, n_input)\n",
    "        outputs: np.array (batch_size, num_steps, n_output)\n",
    "        weights: (Optional) weight of samples np.array (batch_size)\n",
    "        \n",
    "        We need to run train_op to update the parameters\n",
    "        We also need to return its loss\n",
    "        \"\"\"\n",
    "        self.checkInputs(inputs)\n",
    "        \n",
    "        batch_size = inputs.shape[0]\n",
    "        \n",
    "        self.checkOutputs(outputs, batch_size)\n",
    "        \n",
    "        sess = sess or tf.get_default_session()\n",
    "        \n",
    "        feed_dict = {self._input_data: inputs, self._targets: outputs}\n",
    "        \n",
    "        if not initial_state is None:\n",
    "            feed_dict[self.initial_state] = initial_state\n",
    "\n",
    "        if weights is None:\n",
    "            weights = np.ones(batch_size, dtype=np.float32)\n",
    "            \n",
    "        feed_dict[self._weights] = weights\n",
    "        \n",
    "        _, loss, state = sess.run([self.train_op, self.loss, self.final_state], \n",
    "                           feed_dict)\n",
    "        \n",
    "        return loss, state\n",
    "    \n",
    "    def predict(self, inputs, outputs = None, weights = None, sess=None):\n",
    "        \"\"\"\n",
    "        inputs: np.array (batch_size, num_steps, n_input)\n",
    "        outputs: np.array (batch_size, num_steps) or (batch_size)\n",
    "                       or (batch_size, num_steps, n_output) or (batch_size, n_output)\n",
    "        \n",
    "        This function would not run train_op\n",
    "        outputs is only optional if we want to get the loss\n",
    "        \"\"\"\n",
    "        self.checkInputs(inputs)\n",
    "        \n",
    "        if not outputs is None:\n",
    "            batch_size = inputs.shape[0]\n",
    "            self.standardizeOutputs(outputs)\n",
    "            self.checkOutputs(outputs, batch_size)\n",
    "        \n",
    "        sess = sess or tf.get_default_session()\n",
    "        \n",
    "        if weights is None:\n",
    "            weights = np.ones(batch_size, dtype=np.float32)\n",
    "\n",
    "        if not outputs is None:\n",
    "            predicted, loss = sess.run([self.output, self.loss],\n",
    "                    {self._input_data: inputs, self._targets: outputs, self._weights: weights})\n",
    "            return (predicted, loss)\n",
    "        else:\n",
    "            predicted = sess.run(self.output,\n",
    "                    {self._input_data: inputs})\n",
    "            return predicted\n",
    "        \n",
    "    def assign_lr(self, lr_value, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        \n",
    "        sess.run(tf.assign(self.lr, lr_value))\n",
    "        \n",
    "    def get_state(self, sess=None):\n",
    "        \"\"\"\n",
    "        This basically gives the state of the cell\n",
    "        \"\"\"\n",
    "        sess = sess or tf.get_default_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
